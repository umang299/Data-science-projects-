{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_May20_Proj_UmangAgarwal",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvxEcKLpxdF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras \n",
        "import pandas as pd\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0UZOUcfxiZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths = '/content/face-mask-detector-master (1).zip'\n",
        "imgpaths = list(paths.list_images(paths))\n",
        "img = []\n",
        "label = []\n",
        "for imagePath in imgpaths:\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\timage = preprocess_input(image)\n",
        "\timg.append(image)\n",
        "\tlabel.append(label)\n",
        "img = np.array(img, dtype=\"float32\")\n",
        "label = np.array(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFbNAjONYn7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cAC1WndyvMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqDClX0wyyF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb8ncCQky3yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelBinarizer()\n",
        "labels = encoder.fit_transform(label)\n",
        "labels = to_categorical(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cti7ZS78zPau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x,test_x,train_y,test_y = train_test_split(img, label,\n",
        "\ttest_size=0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ4EtPRtzeaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dgen = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptFGxP40ztx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bModel = MobileNetV2(weights=\"imagenet\",\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "a = bModel.output\n",
        "a = AveragePooling2D(pool_size=(7, 7))(a)\n",
        "a = Flatten()(a)\n",
        "a = Dense(128, activation=\"relu\")(a)\n",
        "a = Dropout(0.5)(a)\n",
        "a = Dense(2, activation=\"softmax\")(a)\n",
        "model = Model(inputs=bModel.input, outputs=a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUaFcZ700G_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in bModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-VVdPX80Ww2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = model.fit(dgen.flow(train_x, train_y, batch_size=120), \n",
        "            steps_per_epoch=len(train_x) // batch_size,\n",
        "\t\t\tvalidation_data=(test_x, test_y),\n",
        "\t\t\tvalidation_steps=len(test_x) // batch_size,\n",
        "\t\t\tepochs=18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJEADObO039c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y = model.predict(X_test, batch_size=120)\n",
        "pred_y = np.argmax(pred_y, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCIG4ttL1Mfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classification_report(y_test.argmax(axis=1), y_pred, target_names=encoder.classes_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epuWAc7t1Rc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Model\", save_format=\"h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ahS0k_2t0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.arange(0, epochs), tr.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, epochs), tr.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"upper right\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ckLjsw3B9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prototxtPath = '/content/drive/My Drive/maskclassifier/face_detector/deploy.prototxt'\n",
        "weightsPath = '/content/drive/My Drive/maskclassifier/face_detector/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "face_model = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "model = load_model(\"model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wSbP0iw3vq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread('/content/drive/My Drive/maskclassifier/test/people1.png')\n",
        "height, width = image.shape[:2]\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "face_model.setInput(blob)\n",
        "detections = face_model.forward()\t\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJQAWbjq34MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "threshold = 0.2\n",
        "person_with_mask = 0;\n",
        "person_without_mask = 0;\n",
        "for i in range(0, detections.shape[2]):\n",
        "\tscore = detections[0, 0, i, 2]\n",
        "\tif score > threshold:\n",
        "\t\t#coordinates of the bounding box\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
        "\t\tX_start, Y_start, X_end, Y_end = box.astype(\"int\")\n",
        "\t\tX_start, Y_start = (max(0, X_start), max(0, Y_start))\n",
        "\t\tX_end, Y_end = (min(width - 1, X_end), min(height - 1, Y_end))\n",
        "\n",
        "\t\tface = image[Y_start:Y_end, X_start:X_end]\n",
        "\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\t\t#Convert to rgb\n",
        "\t\tface = cv2.resize(face, (224, 224))\t\t\t\t\t#resize\n",
        "\t\tface = img_to_array(face)\t\t\t\t\t\t\t\n",
        "\t\tface = preprocess_input(face)\n",
        "\t\tface = np.expand_dims(face, axis=0)\t\n",
        "\t\n",
        "\t\tmask, withoutMask = model.predict(face)[0]\t\t\t#To predict mask or not on the face\n",
        "\n",
        "\t\tif mask > withoutMask:\t\t\t\t\t\t\t\t#determining the label\n",
        "\t\t\tlabel = \"Mask\"\n",
        "\t\t\tperson_with_mask += 1\n",
        "\t\telse: \n",
        "\t\t\tlabel = \"No Mask\"\n",
        "\t\t\tperson_without_mask += 1\n",
        "\t\t\t\n",
        "\t\tif label == \"Mask\":\t\t\t\t\t\t\t\t\t#determine the color\n",
        "\t\t\tcolor = (0, 255, 0)\n",
        "\t\telse:\n",
        "\t\t\tcolor = (0, 0, 255)\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\t\t#label and probability\n",
        "\t\tcv2.putText(image, label, (X_start, Y_start - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(image, (X_start, Y_start), (X_end, Y_end), color, 2)\n",
        "  \n",
        "print(\"Number of person with mask : {}\".format(person_with_mask))\n",
        "print(\"Number of person without mask : {}\".format(person_without_mask))\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVuDhPya4CcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}